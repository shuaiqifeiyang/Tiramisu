[{"categories":["CSCI-567 Machine Learning"],"content":"Linear Classifier Classification: N samples/instances: $D^{TRAIN}={(\\vec x_1, y_1),(\\vec x_2, y_2),…,(\\vec x_n, y_n)}$ Each $\\vec x_n \\in \\mathbb{R}^D$ is called a feature vector Each $y_n\\in[C]={1,2,…,C}$ is called a label\\class\\catrgory They are used for learning $f:\\mathbb{R}^D\\rightarrow[C]$ for future prediction This post is focus on binary classification. Number of classes: C=2 Labels: {-1, +1} Model: $\\mathcal F={f(\\vec x)=sign(\\vec w^T\\vec x)|\\vec x\\in\\mathbb{R}^D}$, $sign(\\vec w^T\\vec x)=\\begin{cases} +1\\ if\\ \\vec w^T\\vec x\u003e0\\\\ -1\\ if\\ \\vec w^T\\vec x\\leq0\\ \\end{cases}$ ","date":"2022-02-09","objectID":"/posts/machine-learning/linear-classiifier/:0:0","tags":["Machine Learning"],"title":"Linear Classifier","uri":"/posts/machine-learning/linear-classiifier/"},{"categories":["CSCI-567 Machine Learning"],"content":"Loss Function $z=y_n\\vec w^T\\vec x$ perceptron loss:$l_{\\mathrm{perceptron}}(z)=max{0, -z}$ hinge loss: $l_\\mathrm{hinge}(z)=max{0,1-z}$ logistic loss: $l_\\mathrm{logistic}=log(1-exp(-z))$ ","date":"2022-02-09","objectID":"/posts/machine-learning/linear-classiifier/:1:0","tags":["Machine Learning"],"title":"Linear Classifier","uri":"/posts/machine-learning/linear-classiifier/"},{"categories":["CSCI-567 Machine Learning"],"content":"Find ERM(Empirical Risk Minimization) $\\vec w^\\ast=\\mathop{argmin}\\limits_{\\vec w\\in\\mathbb{R}^D}\\sum\\limits_{n=1}^Nl(y_n\\vec w^T\\vec x_n)$ minimizing perceptron loss does not really make sense (try $\\vec w=\\vec 0$), but the algorithm derived from this perspective does. ","date":"2022-02-09","objectID":"/posts/machine-learning/linear-classiifier/:2:0","tags":["Machine Learning"],"title":"Linear Classifier","uri":"/posts/machine-learning/linear-classiifier/"},{"categories":["CSCI-567 Machine Learning"],"content":"Gradient Descent (GD) Gradient is sometimes referred to as first-order information of a function. Therefore, these methods are called first-order methods. Goal: minimize $F(\\vec w)$ Algorithm: move a bit in the negative gradient direction. $\\vec w^{(t+1)}\\leftarrow\\vec w^{(t)}-\\eta\\nabla F(\\vec w^{(t)})$, where $\\eta\u003e0$ is called step size or learning rate. in theory $\\eta$ should be set in terms of some parameters of $F$ in practice we just try several small values Essentially, GD is Taylor approximation: $F(\\vec w)\\approx F(\\vec w^{(t)})+\\nabla F(\\vec w^{(t)})^T(\\vec w-\\vec w^{(t)})$, we use $-\\eta\\nabla F(\\vec w^{(t)})$ represents $\\vec w-\\vec w^{(t)}$, so $F(\\vec w^{(t+1)})\\approx F(\\vec w^{(t)})-\\eta\\parallel\\nabla F(\\vec w^{(t)})\\parallel_2^2\\leq F(\\vec w^{(t)})$ ","date":"2022-02-09","objectID":"/posts/machine-learning/linear-classiifier/:2:1","tags":["Machine Learning"],"title":"Linear Classifier","uri":"/posts/machine-learning/linear-classiifier/"},{"categories":["CSCI-567 Machine Learning"],"content":"Stochastic Gradient Descent (SGD) $\\vec w^{(t+1)}\\leftarrow\\vec w^{(t)}-\\eta\\tilde\\nabla F(\\vec w^{(t)})$, where $\\tilde\\nabla F(\\vec w^{(t)})$ is a random variable (called stochastic gradient) $\\mathbb{E}[\\tilde\\nabla F(\\vec w^{(t)})]=\\nabla F(\\vec w^{(t)})$ It could be much faster to obtain a stochastic gradient! Convergence guarantees for both GD and SGD on convex objectives. ","date":"2022-02-09","objectID":"/posts/machine-learning/linear-classiifier/:2:2","tags":["Machine Learning"],"title":"Linear Classifier","uri":"/posts/machine-learning/linear-classiifier/"},{"categories":["CSCI-567 Machine Learning"],"content":"Applying GD to perceptron loss $F(\\vec w)=\\sum\\limits_{n=1}^Nmax{0, -y_n\\vec w^T\\vec x_n}$ $\\nabla F(\\vec w)=\\sum\\limits_{n=1}^N-\\mathbb{I}[y_n\\vec w^T\\vec x_n\\leq0]y_n\\vec x_n$, only misclassified examples contribute to the gradient GD update: $\\vec w\\leftarrow\\vec w+\\eta\\sum\\limits_{n=1}^N\\mathbb{I}[y_n\\vec w^T\\vec x_n\\leq0]y_n\\vec x_n$ Each update makes one pass of the entire training set ","date":"2022-02-09","objectID":"/posts/machine-learning/linear-classiifier/:2:3","tags":["Machine Learning"],"title":"Linear Classifier","uri":"/posts/machine-learning/linear-classiifier/"},{"categories":["CSCI-567 Machine Learning"],"content":"Applying SGD to perception loss How to construct a stochastic gradient? Pick one example $n\\in[N]$ uniformly at random, $\\tilde\\nabla F(\\vec w)=-N\\mathbb{I}[y_n\\vec w^T\\vec x_n\\leq0]y_n\\vec x_n$ SGD update: $\\vec w\\leftarrow\\vec w+\\eta\\mathbb{I}[y_n\\vec w^T\\vec x_n\\leq0]y_n\\vec x_n$ ($\\eta$ absorbing the constant N) (each update touches only one data point!) ","date":"2022-02-09","objectID":"/posts/machine-learning/linear-classiifier/:2:4","tags":["Machine Learning"],"title":"Linear Classifier","uri":"/posts/machine-learning/linear-classiifier/"},{"categories":["CSCI-567 Machine Learning"],"content":"Perceptron Algorithm Perceptron algorithm is SGD with $\\eta=1$ applied to perceptron loss: Repeat: Pick a data point $\\vec x_n$ uniformly at random If $sgn(\\vec w^T\\vec x_n)\\neq y_n$, $\\vec w\\leftarrow\\vec w+y_n\\vec x_n$ Note: $\\vec w$ is always a linear combination of the training examples. $\\eta=1$ does not really matter in terms of training error. If training set is linearly separable perceptron converges in a finite number of stpes training error is 0 sigmoid function: $\\sigma(z)=\\frac{1}{1+e^{(-z)}}$ $\\sigma(z)$ is between 0 and 1 $\\sigma(\\vec w^T\\vec x)\u003e=0.5 \\Leftrightarrow\\vec w^T\\vec x\\geq0$, consistent with predicting the label with $sign(\\vec w^T\\vec x)$ larger $\\vec w^T\\vec x\\Rightarrow$ larger $\\sigma(\\vec w^T\\vec x)\\Rightarrow$ higher confidence in label 1 $\\sigma(z)+\\sigma(-z)=1$ for all $z$ ","date":"2022-02-09","objectID":"/posts/machine-learning/linear-classiifier/:2:5","tags":["Machine Learning"],"title":"Linear Classifier","uri":"/posts/machine-learning/linear-classiifier/"},{"categories":["CSCI-567 Machine Learning"],"content":"Linear Regression Regression VS Classification continuous vs discrete measure prediction error differently Measure error for one prediction absolute error: |prediction - sale price| squared error: (prediction - sale price)^2 Formal set up for linear regression input: $\\vec x\\in\\mathbb{R}^D$ Output: $y\\in\\mathbb{R}$ Training data: $D={(\\vec{x_n}, y_n),n=1,2,…,N}$ Linear model: $f:\\mathbb{R}^D\\rightarrow\\mathbb{R}$, with $f(\\vec{x})=w_0+\\sum_{d=1}^{D}w_dx_d=w_0+\\vec{w}^T\\vec{x}$ For notation convenience $f(\\vec{x})=\\tilde{\\boldsymbol{w}}^T\\tilde{\\boldsymbol{x}}=\\tilde{\\boldsymbol{x}}^T\\tilde{\\boldsymbol{w}}$, where $\\tilde{\\boldsymbol{w}}=[w_0,w_1,w_2,…,w_D]^T,\\tilde{\\boldsymbol{x}}=[1,x_1,x_2,…,x_D]^T$ RSS(Residual sum of squares) $RSS(\\tilde{\\boldsymbol{w}})=\\sum\\limits_{n}(f(\\vec{x_n})-y_n)^2=\\sum\\limits_{n}(\\tilde{\\boldsymbol{w}}^T\\tilde{\\boldsymbol{x}}_n-y_n)^2=\\sum\\limits_{n}(\\tilde{\\boldsymbol{x}}_n^T\\tilde{\\boldsymbol{w}}-y_n)^2$ Empirical risk minimizer/Least squares solution $\\tilde{\\boldsymbol{w}}^\\ast=\\mathop{argmin}\\limits_{\\tilde{\\boldsymbol{w}}\\in\\mathbb{R}^{D+1}}\\ RSS(\\tilde{\\boldsymbol{w}})$ General Least Square Solution Object: $RSS(\\tilde{\\boldsymbol{w}})=\\sum\\limits_{n}(\\tilde{\\boldsymbol{w}}^T\\tilde{\\boldsymbol{x}}_n-y_n)^2$ $\\nabla RSS(\\tilde{\\boldsymbol{w}})=2\\sum\\limits_{n}\\tilde{\\boldsymbol{x}}_n(\\tilde{\\boldsymbol{w}}^T\\tilde{\\boldsymbol{x}}_n-y_n)\\propto\\sum\\limits_{n}\\tilde{\\boldsymbol{x}}_n\\tilde{\\boldsymbol{x}}_n^T\\tilde{\\boldsymbol{w}}-\\sum\\limits_ny_n\\tilde{\\boldsymbol{x}}_n$ notation: $\\tilde{\\boldsymbol{X}}=\\begin{pmatrix} \\tilde{\\boldsymbol{x}}_1^T\\\\ \\tilde{\\boldsymbol{x}}_2^T\\\\ \\vdots\\\\ \\tilde{\\boldsymbol{x}}_N^T \\end{pmatrix}\\in\\mathbb{R}^{N\\times(D+1)},\\tilde{\\boldsymbol{y}}=\\begin{pmatrix} y_1\\\\ y_2\\\\ \\vdots\\\\ y_n \\end{pmatrix}\\in\\mathbb{R}^{N\\times1}$ $\\nabla RSS(\\tilde{\\boldsymbol{w}})=(\\tilde{\\boldsymbol{X}}^T\\tilde{\\boldsymbol{X}})\\tilde{\\boldsymbol{w}}-\\tilde{\\boldsymbol{X}}^T\\boldsymbol{y}=0$ $\\tilde{\\boldsymbol{w}}^\\ast=(\\tilde{\\boldsymbol{X}}^T\\tilde{\\boldsymbol{X}})^{-1}\\tilde{\\boldsymbol{X}}^T\\boldsymbol{y}$ When $D=0,(\\tilde{\\boldsymbol{X}}^T\\tilde{\\boldsymbol{X}})^{-1}=\\frac{1}{N},\\tilde{\\boldsymbol{X}}^T\\boldsymbol{y}=\\sum_n y_n,\\tilde{\\boldsymbol{w}}^\\ast=\\frac{\\sum_n y_n}{N}$ Invert the matrix $\\tilde{\\boldsymbol{X}}^T\\tilde{\\boldsymbol{X}}$ takes $O(D^3)$ What if $\\tilde{\\boldsymbol{X}}^T\\tilde{\\boldsymbol{X}}$ is not invertible When $n\u003cD+1$, not enough data to estimate all parameters. $\\tilde{\\boldsymbol{X}}^T\\tilde{\\boldsymbol{X}}$ is symmetric eigen decomposition: $\\tilde{\\boldsymbol{X}}^T\\tilde{\\boldsymbol{X}}=\\boldsymbol{U}^T\\begin{bmatrix}\\lambda_1\u00260\u0026\\cdots\u00260\\\\0\u0026\\lambda_2\u0026\\cdots\u00260\\\\\\vdots\u0026\\vdots\u0026\\vdots\u0026\\vdots\\\\0\u0026\\cdots\u0026\\lambda_{D}\u00260\\\\0\u0026\\cdots\u00260\u0026\\lambda_{D+1}\\end{bmatrix}\\boldsymbol{U}$ $(\\tilde{\\boldsymbol{X}}^T\\tilde{\\boldsymbol{X}})^{-1}=\\boldsymbol{U}^T\\begin{bmatrix}1/\\lambda_1\u00260\u0026\\cdots\u00260\\\\0\u00261/\\lambda_2\u0026\\cdots\u00260\\\\\\vdots\u0026\\vdots\u0026\\vdots\u0026\\vdots\\\\0\u0026\\cdots\u00261/\\lambda_{D}\u00260\\\\0\u0026\\cdots\u00260\u00261/\\lambda_{D+1}\\end{bmatrix}\\boldsymbol{U}$ Non-invertible means some eigenvalues are zero One natural fix: add something positive: $\\tilde{\\boldsymbol{X}}^T\\tilde{\\boldsymbol{X}}+\\lambda\\boldsymbol{I}=\\boldsymbol{U}^T\\begin{bmatrix}\\lambda_1+\\lambda\u00260\u0026\\cdots\u00260\\\\0\u0026\\lambda_2+\\lambda\u0026\\cdots\u00260\\\\\\vdots\u0026\\vdots\u0026\\vdots\u0026\\vdots\\\\0\u0026\\cdots\u0026\\lambda_{D}+\\lambda\u00260\\\\0\u0026\\cdots\u00260\u0026\\lambda_{D+1}+\\lambda\\end{bmatrix}\\boldsymbol{U}$ The solution becomes: $\\tilde{\\boldsymbol{w}}^\\ast=(\\tilde{\\boldsymbol{X}}^T\\tilde{\\boldsymbol{X}}+\\lambda\\boldsymbol{I})^{-1}\\tilde{\\boldsymbol{X}}^T\\boldsymbol{y}$ Parametric VS Non-parametric: Parametric methods: the size of the model does not grow with the size of the training set N Non-parametric methods: the size of the model grows with the size of the training set ","date":"2022-02-01","objectID":"/posts/machine-learning/linear-regression/:0:0","tags":["Machine Learning"],"title":"Linear Regression","uri":"/posts/machine-learning/linear-regression/"},{"categories":["CSCI-567 Machine Learning"],"content":"Linear regression with nonlinear basis Use a nonlinear mapping: $\\phi(\\vec x):\\vec x\\in\\mathbb{R}^D\\rightarrow\\vec z\\in\\mathbb{R}^M$, transform the data to a more complicated feature space. Then apply linear regression. Model: $f(\\vec x)=\\vec w^T\\phi(\\vec x)$, where $\\vec w\\in\\mathbb{R}^M$ Objective: $RSS(\\vec w)=\\sum\\limits_{n}(\\vec w^T\\phi(\\vec x_n)-y_n)^2$ Least square solution: $\\vec w^\\ast=(\\boldsymbol\\Phi^T\\boldsymbol\\Phi)^{-1}\\boldsymbol\\Phi^T\\vec y$, where $\\boldsymbol{\\Phi}=\\begin{pmatrix} \\phi(\\boldsymbol{x}_1)^T\\\\ \\phi(\\boldsymbol{x}_2)^T\\\\ \\vdots\\\\ \\phi(\\boldsymbol{x}_3)^T \\end{pmatrix}\\in\\mathbb{R}^{N\\times M}$ Underfitting: large training error large test error overfitting: small training error large test error How to prevent overfitting: use more data control the model complexity For polynomial basis, the degree M clearly controls the complexity Use cross-validation to pick hyper-parameter M Regularized linear regression: $\\varepsilon(\\vec w)=RSS(\\vec w)+\\lambda R(\\vec w)$ ","date":"2022-02-01","objectID":"/posts/machine-learning/linear-regression/:1:0","tags":["Machine Learning"],"title":"Linear Regression","uri":"/posts/machine-learning/linear-regression/"},{"categories":["CSCI-567 Machine Learning"],"content":"Nearest Neighbor Classifier Training Data: N samples/instances: $D^{TRAIN}={(\\vec x_1, y_1),(\\vec x_2, y_2),…,(\\vec x_n, y_n)}$ Each $\\vec x_n \\in \\mathbb{R}^D$ is called a feature vector Each $y_n\\in[C]={1,2,…,C}$ is called a label\\class\\catrgory They are used for learning $f:\\mathbb{R}^D\\rightarrow[C]$ for future prediction Nearest neighbor: $\\vec x(1)=\\vec x_{nn(\\vec{x})}$, $nn(\\vec x)\\in[N]={1,2,…,N}$where $nn(x)$ is the index to one of the training instances, $nn(\\vec{x})=\\mathop{argmin}\\limits_{n\\in[N]}\\parallel\\vec{x}-\\vec{x_n}\\parallel_2=\\mathop{argmin}\\limits_{n\\in[N]}\\sqrt{\\sum\\limits_{d=1}^D(x_d-x_{nd})^2}$ Classification rule: $y=f(\\vec{x})=y_{nn(\\vec x)}$ Decision boundary: for every point in the space, we can determine its label using the NNC rule. This gives rise to a decision boundary that partitions the space into different regions. Accuracy: the percentage of data points being correctly classified. Error Rate: the percentage of data points being incorrectly classified. Accuracy+Error Rate=1 Accuracy and Error Rate defined on the training data set: $A^{TRAIN}=\\frac{1}{N}\\sum\\limits_n\\mathbb{I}[f(\\vec{x_n})==y_n]$ $\\varepsilon^{TRAIN}=\\frac{1}{N}\\sum\\limits_n\\mathbb{I}[f(\\vec{x_n})\\neq y_n]$ $\\mathbb{I}(e)$ is the indicator function: $$\\mathbb{I}(e)=\\begin{cases} 1\\ if\\ e\\ is\\ true \\\\ 0\\ if\\ e\\ is\\ false \\ \\end{cases}$$ For NNC, $A^{TRAIN}=100%$,$\\varepsilon^{TRAIN}=0$ Test/Evaluation data $D^{TEST}={(\\vec x_1, y_1),(\\vec x_2, y_2),…,(\\vec x_m, y_m)}$ A fresh dataset, not overlap with training set Test accuracy and test error $A^{TRAIN}=\\frac{1}{M}\\sum\\limits_m\\mathbb{I}[f(\\vec{x_m})==y_m]$ $\\varepsilon^{TRAIN}=\\frac{1}{M}\\sum\\limits_m\\mathbb{I}[f(\\vec{x_m})\\neq y_m]$ Test accuracy and test error are better measurement than train accuracy and train error Variant of NNC measure nearness with other distances, for example $L_p$ distance: $\\parallel\\vec {x}-\\vec{x_n}\\parallel_p=(\\sum\\limits_d |x_d-x_{nd}|^p)^\\frac{1}{p}$, for $p\\geq1$ K-nearest neighbor, every neighbor votes for its lable. Predict with the majority with K increases, the decision boundary becomes smoother Preprocessing data. One issue of NNC: distances depend on units of the features. We can process data so it looks more “normalized”. Compute the means and standard deviations in each feature $\\bar{x_d}=\\frac{1}{N}\\sum\\limits_n x_{nd}$ $s_d^2=\\frac{1}{N-1}\\sum\\limits_n(x_{nd}-\\bar{x_d})^2$ Scale the feature accordingly $x_{nd}\\leftarrow\\frac{x_{nd}-\\bar{x_d}}{s_d}$ Hyper-parameters in NCC The distance measure (e.g. the parameter $p$ for $L_P$ norm) K (how many nearest neighbor) Different ways of preprocessing data Dataset Training data are used for learning $f(\\cdot)$ Test data are used for assessing how well $f(\\cdot)$ do Development/Validation data are used to optimize hyper-parameters. Recipe For each possible value of the hyperparameter Train a model using $D^{TRAIN}$ Evaluate the performance of the model on $D^{DEV}$ Choose the model with the best performance on $D^{DEV}$ Evaluate the model on $D^{TEST}$ S-fold Cross-validation When we do not have a development set Split the training data in to S equal parts Use each part in turn as a development dataset and use the others as a training dataset Choose the hyper-parameter leading to best average performance Use the best hyper-parameter to train a model using all $D^{TRAIN}$ Advantage of NNC Simple, easy to implement Disadvantage of NNC Computationally intensive for large scale problems: $O(ND)$ for each prediction. Need to carry the training data around. This type of method is called nonparametric Choosing the right hyper-parameters can be involved Typical steps of development a machine learning system Collect data, split into training, development, and test sets. Train a model with a machine learning algorithm. Most often we apply cross-validation to tune hyper-parameters. Evaluate using the test data and report performance Use the model to predict future/make decisions. ","date":"2022-01-28","objectID":"/posts/machine-learning/nnc/:0:0","tags":["Machine Learning"],"title":"NNC","uri":"/posts/machine-learning/nnc/"},{"categories":["CSCI-567 Machine Learning"],"content":"How good is NNC? Most standard assumption: every data point $(\\vec{x}, y)$ (from $D^{TRAIN},D^{DEV},D^{TEST}$) is an independent identically distribution (i.i.d) sample of an unknown joint distribution $P$. often written as $(\\vec{x}, y) \\mathop{\\sim}\\limits^{i.i.d}P$ Test error of a fixed classifier is therefore a random variable, and the expectation of test error is the expected error\\mistake of $f$ $E[\\varepsilon^{TEST}]=\\frac{1}{M}\\sum\\limits_{m=1}^{M}E_{(\\vec{x_m}, y_m)\\sim P}\\mathbb{I}[f(\\vec{x_m})\\neq y_m]=E_{(\\vec{x}, y)\\sim P}\\mathbb{I}[f(\\vec{x})\\neq y]$ Test error is a proxy of expected error. The larger the test set, the better the approximation. Expected risk More generally, for a loss funcion $L(y^\\prime, y)$, the expected risk of $f$ is defined as $R(f)=E_{(\\vec x, y)\\sim P}L(f(\\vec x), y)$ $L(y^\\prime, y)=\\mathbb{I}[y^\\prime \\neq y]$ called 0-1 loss Bayes optimal classifier: $f^\\ast(x)=\\mathop{argmax}\\limits_{c\\in[C]}P(c|x)$ The optimal risk: $R(f^\\ast)=E_{x\\sim P_x}[1-max_{c\\in[C]}P(c|x)]$ where $P_x$ is the marginal distribution of x. It is easy to show $R(f^\\ast)\\leq R(f)$ for any $f$. For special case $C=2$, let $\\eta(x)=P(0|x)$, then $R(f^\\ast)=E_{x\\sim P_x}[min{\\eta(x), 1-\\eta(x)}]$ ","date":"2022-01-28","objectID":"/posts/machine-learning/nnc/:1:0","tags":["Machine Learning"],"title":"NNC","uri":"/posts/machine-learning/nnc/"},{"categories":["Projects"],"content":"Simulation of Roulette in Las Vegas Casinos ","date":"2022-01-19","objectID":"/posts/projects/roulette/:0:0","tags":["React"],"title":"Roulette","uri":"/posts/projects/roulette/"},{"categories":["Projects"],"content":"Introduction You can play it online. Github Repository This game is developed with ReactJS. ","date":"2022-01-19","objectID":"/posts/projects/roulette/:1:0","tags":["React"],"title":"Roulette","uri":"/posts/projects/roulette/"},{"categories":["Projects"],"content":"Implementation ","date":"2022-01-19","objectID":"/posts/projects/roulette/:2:0","tags":["React"],"title":"Roulette","uri":"/posts/projects/roulette/"},{"categories":["Projects"],"content":"How to implement the layout in Roulette Table? Where we put chips like this: In CSS, Grid layout perfectly fits out needs. We use grid-template-areas divide each area. Then we use grid-area place blocks to corresponding area. ","date":"2022-01-19","objectID":"/posts/projects/roulette/:2:1","tags":["React"],"title":"Roulette","uri":"/posts/projects/roulette/"},{"categories":["Projects"],"content":"How to draw circle using CSS? div{ width: 100px; height: 100px; border-radius: 50%; } ","date":"2022-01-19","objectID":"/posts/projects/roulette/:2:2","tags":["React"],"title":"Roulette","uri":"/posts/projects/roulette/"},{"categories":["CSCI-567 Machine Learning"],"content":"Prerequisite knowledge of CSCI-567 Machine Learning Sample Space$(\\Omega)$: set of all possible outcomes or realizations Event$(A)$: A subset of sample space Probability: We assign a real number $P(A)$ to each event $A$, called the probability of $A$ Probability Axioms: $P(A)\\ge0$ for every $A$ $P(\\Omega)=1$ If $A_1, A_2,…$ are disjoints, then $P(\\bigcup_{i=1}^{\\infty}A_i)=\\sum_{i=1}^{\\infty}P(A_i)$ Random Variable: A random variable is a measurable function that maps a probability space into a measurable space. A random variable is a variable whose values depend on outcomes of a random event. The data are specific realizations of random variables A statistic is just any function of the data or random variable. Distribution Function Definition: Suppose $X$ is a random variable, $x$ is a specific value of it, Cumulative Distribution Function is the function $F:R\\rarr[0,1]$ ,where $F(x)=P(X\\leq x)$ If $X$ is discrete $\\Rightarrow$ probability mass function: $f(x)=P(X=x)$ If $X$ is continuous $\\Rightarrow$ probability density function for $X$ if there exists a function $F$ such that $f(x)\\geq 0$ for all $x$, $\\int_{-\\infty}^{\\infty}f(x)dx=1$ and for every $a\\leq b$, $$ P(a\\leq X\\leq b)=\\int_a^bf(x)dx $$ If $F(x)$ is differentiable everywhere, $f(x)=F^\\prime(x)$ Expected Values Discrete random variable X, $E[g(X)]=\\sum_{x\\in \\chi}g(x)f(x)$ Continuous random variable X, $E[g(x)]=\\int_{-\\infty}^\\infty g(x)f(x)$ Mean and Variance $\\mu=E[X]$ is the mean; $var[X]=E[(X-\\mu)^2]$ is the variance. We also have $var[X]=E[X^2]-\\mu^2$ Common Distributions Multivariate Distributions $F_{X,Y}(x,y):=P(X\\leq x,Y\\leq y)$ $f_{X,Y}(x,y):=\\frac{\\partial^2F_{X,Y}(x,y)}{\\partial x\\partial y}$ Marginal Distribution of X(Discrete case): $f_X(x)=P(X=x)=\\sum_yP(X=x,Y=y)=\\sum_yF_{X,Y}(x,y)$ or $F_X(x)=\\int_yf_{X,Y}(x,y)dy$ for continuous variable Conditional probability of $X$ given $Y=y$ is $f_{X|Y}(x|y)=P(X=x|Y=y)=\\frac{P(X=x,Y=y)}{P(Y=y)}=\\frac{f_{X,Y}(x,y)}{F_Y(y)}$ Law of total Probability:$X$ takes values $x_1,…,x_n$ and y is a value of Y, we have $$ F_Y(y)=\\sum_jf_{Y|X}(y|x_j)f_X(x_j) $$ Bayes Rule: $$ P(A|B)=\\frac{P(B|A)P(A)}{P(B)} $$ $$ f_{X|Y}(x_i|y)=\\frac{f_{Y|X}(y|x_i)f_X(x_i)}{\\sum_jf_{Y|X}(y|x_j)f_X(x_j)} $$ $$ f_{X|Y}(x|y)=f_{X|Y}(x_i|y)=\\frac{f_{Y|X}(y|x_i)f_X(x_i)}{\\int_xf_{Y|X}(y|x)f_X(x)dx} $$ Independent Variables $X$ and $Y$ are independent if and only if: $P(X=x, Y=y)=P(X=x)P(Y=y)$ or $f_{X,Y}(x,y)=f_X(x)f_y(y)$ for all values $x$ and $y$. IID variables: Independent and identically distributed random variables are drawn from the same distribution and are all mutually independent. If $X_1,…X_n$ are independent, we have $$ E[\\prod_{i=1}^{n}X_i]=\\prod_{i=1}^{n}E[X_i], var[\\sum_{i=1}^na_iX_i]=\\sum_{i=1}^na_i^2var[X_i] $$ Linearity of Expectation: Even if $X_1,…,X_n$ are not independent, $$ E[\\sum_{i=1}^nX_i]=\\sum_{i=1}^nE[X_i] $$ Covariance $$ cov(X,Y)=E[(X-\\mu_x)(Y-\\mu_y)]=E[X\\cdot Y]-\\mu_x\\mu_y $$ Correlation coefficients $$ corr(X,Y)=Cov(X,Y)/\\sigma_x\\sigma_y $$ ($\\sigma$: standard deviation) Sample Mean: $$\\overline{X}=\\frac{1}{N}\\sum_{i=1}^NX_i $$ Sample Variance: $$ S^2=\\frac{1}{N-1}\\sum_{i=1}^N(X_i-\\overline X)^2 $$ If $X_i$ are iid: $$ E[\\overline X]=E[X_i]=\\mu $$ $$ Var(\\overline X)=\\sigma^2/N $$ $$ E[S^2]=\\sigma^2 $$ Point Estimation The point estimator $\\hat{\\theta}_N$ is a function of samples $X_1,…,X_N$ that approximates a parameter $\\theta$ of the distribution of $X_i$. Sample Bias: the bias of an estimator is $$ bias(\\hat{\\theta}N)=E\\theta[\\hat\\theta_N]-\\theta $$ An estimator is unbiased estimator if $E_\\theta[\\hat\\theta_N]=\\theta$ Standard error: the standard deviation of $\\hat\\theta_N$ is called the standard error $$ se(\\hat\\theta_N)=\\sqrt{Var(\\hat\\theta_N)} $$ Information Theory Suppose $X$ can have one of the m values: $x_1, x_2,…,x_m$. The probability distribution is $P(X=x_i)=p_i$ Entropy: $H(X)=-\\sum_{j=1}^{m}p_i\\log p_i$ “High entropy” means X is from a uniform distribution “Low entropy” means X is from varied distri","date":"2022-01-13","objectID":"/posts/machine-learning/basic-concepts/:0:0","tags":["Machine Learning"],"title":"ML Basic Concepts","uri":"/posts/machine-learning/basic-concepts/"},{"categories":["Misc"],"content":"Using net module in NodeJS to build a simple TCP socket server ","date":"2022-01-07","objectID":"/posts/misc/tcp-socket-server-node/:0:0","tags":["NodeJS"],"title":"How to build a TCP socket server in NodeJS","uri":"/posts/misc/tcp-socket-server-node/"},{"categories":["Misc"],"content":"Start a TCP server const Ner=require(\"net\"); const server = Net.createServer(); server.listen(port, function(){ console.log(`Server listening on ${port}`); }) ","date":"2022-01-07","objectID":"/posts/misc/tcp-socket-server-node/:1:0","tags":["NodeJS"],"title":"How to build a TCP socket server in NodeJS","uri":"/posts/misc/tcp-socket-server-node/"},{"categories":["Misc"],"content":"Receive data from socket server.on(\"connection\", function (socket) { console.log(\"A new connection has been established.\"); // write data to socket socket.write(\"hello\\n\"); socket.on(\"data\", function (chunk) { let data=chunk.toString(); // close socket socket.destroy(); }); // When the client requests to end the TCP connection with the server, the server // ends the connection. socket.on(\"end\", function () { console.log(\"Closing connection by the client\"); }); socket.on(\"error\", function (err) { console.log(`Error: ${err}`); }); }); ","date":"2022-01-07","objectID":"/posts/misc/tcp-socket-server-node/:2:0","tags":["NodeJS"],"title":"How to build a TCP socket server in NodeJS","uri":"/posts/misc/tcp-socket-server-node/"},{"categories":["Projects"],"content":"The implementation of Siggraph01 Procedural Modeling of Cities This repository is an implementation of Siggraph01 Procedural Modeling of Cities. We refer to this article and simplify L-System in this paper to a Priority Queue implementation. ","date":"2021-11-28","objectID":"/posts/projects/procedural-modeling-of-cities/:0:0","tags":["Graphics","Unity"],"title":"Procedural Modeling of Cities","uri":"/posts/projects/procedural-modeling-of-cities/"},{"categories":["Projects"],"content":"Input ","date":"2021-11-28","objectID":"/posts/projects/procedural-modeling-of-cities/:1:0","tags":["Graphics","Unity"],"title":"Procedural Modeling of Cities","uri":"/posts/projects/procedural-modeling-of-cities/"},{"categories":["Projects"],"content":"Path generation ","date":"2021-11-28","objectID":"/posts/projects/procedural-modeling-of-cities/:2:0","tags":["Graphics","Unity"],"title":"Procedural Modeling of Cities","uri":"/posts/projects/procedural-modeling-of-cities/"},{"categories":["Projects"],"content":"Highways ","date":"2021-11-28","objectID":"/posts/projects/procedural-modeling-of-cities/:2:1","tags":["Graphics","Unity"],"title":"Procedural Modeling of Cities","uri":"/posts/projects/procedural-modeling-of-cities/"},{"categories":["Projects"],"content":"Highways + Streets ","date":"2021-11-28","objectID":"/posts/projects/procedural-modeling-of-cities/:2:2","tags":["Graphics","Unity"],"title":"Procedural Modeling of Cities","uri":"/posts/projects/procedural-modeling-of-cities/"},{"categories":["Projects"],"content":"Buildings ","date":"2021-11-28","objectID":"/posts/projects/procedural-modeling-of-cities/:3:0","tags":["Graphics","Unity"],"title":"Procedural Modeling of Cities","uri":"/posts/projects/procedural-modeling-of-cities/"},{"categories":["CSCI-570 Analysis of Algorithm"],"content":"NP and Computational Intractability Definition If Problem X is at least as hard as Problem Y, it means that if we could solve X, we could also solve Y. $Y\\le _{p}X$ Y is polynomial-time reducible to X Y can be solved using a polynomial number of computational steps plus a polynomial number of calls to a blackbox that solves X X is at least as hard as Y ","date":"2021-11-18","objectID":"/posts/algorithm/np/:0:0","tags":["Algorithm"],"title":"NP","uri":"/posts/algorithm/np/"},{"categories":["CSCI-570 Analysis of Algorithm"],"content":"Some NP Problems ","date":"2021-11-18","objectID":"/posts/algorithm/np/:1:0","tags":["Algorithm"],"title":"NP","uri":"/posts/algorithm/np/"},{"categories":["CSCI-570 Analysis of Algorithm"],"content":"Independent Set Given a graph $G=(V, E)$, we say a set of nodes $S\\subseteq V$ is independent if no two nodes in S are joined by an edge. Optimization Version: find the maximum size of an independent set. Decision Version: whether G has an independent set of size at least a given k. ","date":"2021-11-18","objectID":"/posts/algorithm/np/:1:1","tags":["Algorithm"],"title":"NP","uri":"/posts/algorithm/np/"},{"categories":["CSCI-570 Analysis of Algorithm"],"content":"Vertex Cover Given a graph $G=(V, E)$, we say that a set of nodes $S\\subseteq V$ is a vertex cover if every edge in E has at least one end in S. Let $G=(V, E)$, then $S$ is a independent set if and only if its complement $V-S$ is a vertex cover set. Independent Set $\\le _{p}$ Vertex Cover. Vertex Cover $\\le _{p}$ Independent Set. Vertex Cover Problem and Independent Set Problem are in the same complexity class. Let $G = (V , E)$ be a graph. Then S is an independent set if and only if its complement V − S is a vertex cover. ","date":"2021-11-18","objectID":"/posts/algorithm/np/:1:2","tags":["Algorithm"],"title":"NP","uri":"/posts/algorithm/np/"},{"categories":["CSCI-570 Analysis of Algorithm"],"content":"Set Cover Given a set $U$ of $n$ elements, a collection $S_1$, . . . , $S_m$ of subsets of $U$, and a number $k$, does there exist a collection of at most $k$ of these sets whose union is equal to all of $U$? Vertex Cover $\\le _{p}$ Set Cover ","date":"2021-11-18","objectID":"/posts/algorithm/np/:1:3","tags":["Algorithm"],"title":"NP","uri":"/posts/algorithm/np/"},{"categories":["CSCI-570 Analysis of Algorithm"],"content":"Satisfiability Problem (SAT) Given a set $X$ of n Boolean variables $x_1,\\dots,x_n$ A clause is simply a disjunction of distince terms $t_1\\lor t_2 \\lor \\cdots\\lor t_l (t_i\\in{x_1,x_2,\\dots,x_n,\\overline{x_1},\\dots,\\overline{x_n} })$. We say the clause has length $l$ if it contains $l$ terms A truth assignment for $X$ is an assignment of the value 0 or 1 to each $x_i$; in other words, it is a function $v: X\\rarr {0, 1}$ An assignment satisfies a clause $C$ if it causes $C$ to evaluate to 1 under the rules of Boolean logic. An assignment satisfies a collection of clauses $C_1,\\dots, C_k$ if it causes all of the $C_i$ to evaluate to 1. In this case, we will say that $v$ is a satisfying assignment with respect to $C_1,\\dots,C_k$; and that the set of clauses $C_1,\\dots,C_k$ is satisfiable. Problem Statement Given a set of clauses $C_1,\\dots,C_k$ over a set of variables $X={x_1,\\dots,x_n}$, does there exist a satisfying truth assignment? 3-SAT: all clauses contain exactly three terms efficient certification: to show efficient certification: Polynomial length certificate Polynomial time certifier the certifier is basically an algorithm that takes the certificate and decides whether or not it is a good solution. NP(Non deterministic polynomial) is the set of all problems for which there exists an efficient certifier. ","date":"2021-11-18","objectID":"/posts/algorithm/np/:1:4","tags":["Algorithm"],"title":"NP","uri":"/posts/algorithm/np/"},{"categories":["CSCI-570 Analysis of Algorithm"],"content":"The Hamiltonian Cycle Problem Given a directed graph $G=(V, E)$, we say that a cycle in G is Hamiltonian Cycle if it visits each vertex exactly once. The Hamiltonian Cycle Problem is then simply the following: Given a directed graph G, does it contain a Hamiltonian cycle? Show Hamiltonian Cycle Problem is NP-Complete: Prove Vertex Cover is polynomial reducible to Hamiltonian Cycle Problem ","date":"2021-11-18","objectID":"/posts/algorithm/np/:1:5","tags":["Algorithm"],"title":"NP","uri":"/posts/algorithm/np/"},{"categories":["CSCI-570 Analysis of Algorithm"],"content":"The Traveling Salesman Problem Order the cities into a tour $v_{i_1}, v_{i_2}, \\dots ,v_{i_n}$, with $i_1=1$, so as to minimize the total distance $\\sum_jd(v_{i_j}, v_{i_{j+1}}) + d(v_{i_n}, v_{i_1})$ Decision version of the Traveling Salesman Problem: Given a set of distances on n cities, and a bound D, is there a tour of length at most D? TSP is polynomial reducible to Hamiltonian Cycle Problem ","date":"2021-11-18","objectID":"/posts/algorithm/np/:1:6","tags":["Algorithm"],"title":"NP","uri":"/posts/algorithm/np/"},{"categories":["CSCI-570 Analysis of Algorithm"],"content":"Prove a problem is NP-Complete Prove X belongs to NP Choose a problem Y that is known to be NP-Complete Prove that Y$\\leq_p$X ","date":"2021-11-18","objectID":"/posts/algorithm/np/:2:0","tags":["Algorithm"],"title":"NP","uri":"/posts/algorithm/np/"},{"categories":["Projects"],"content":"A renderer supporting rasterization, transformation, Phong shading, texture. ","date":"2021-11-08","objectID":"/posts/projects/gzrender/:0:0","tags":["Graphics","C++"],"title":"GzRender","uri":"/posts/projects/gzrender/"},{"categories":["Projects"],"content":"Rasterization Use barycentric coordinates to determine wheter a pixel is in a triangle. $(x_0, y_0),(x_1,y_1),(x_2,y_2)$ are three vertexex of a triangle. w $x_{min}=floor(x_i)$ $x_{max}=ceiling(x_i)$ $y_{min}=floor(y_i)$ $y_{max}=ceiling(y_i)$ for $y=y_{min}$ to $y_{max}$ do for $x=x_{min}$ to $x_{max}$ do $\\alpha=f_{12}(x,y)/f_{12}(x_0, y_0)$ $\\beta=f_{20}(x,y)/f_{20}(x_1, y_1)$ $\\gamma=f_{01}(x,y)/f_{01}(x_2, y_2)$ if ($\\alpha\u003e0$ and $\\beta\u003e0$ and $\\gamma\u003e0$) then $c=\\alpha c_0+\\beta c_1+\\gamma c_2$ drawpixal($x$, $y$) with color $c$ Here $f_{ij}:$ $f_{01}(x, y)=(y_0-y_1)x+(x_1-x_0)y+x_0y_1-x_1y_0$ $f_{12}(x, y)=(y_1-y_2)x+(x_2-x_1)y+x_1y_2-x_2y_1$ $f_{20}(x, y)=(y_2-y_0)x+(x_0-x_2)y+x_2y_0-x_0y_2$ ","date":"2021-11-08","objectID":"/posts/projects/gzrender/:1:0","tags":["Graphics","C++"],"title":"GzRender","uri":"/posts/projects/gzrender/"},{"categories":["Projects"],"content":"Transformation ","date":"2021-11-08","objectID":"/posts/projects/gzrender/:2:0","tags":["Graphics","C++"],"title":"GzRender","uri":"/posts/projects/gzrender/"},{"categories":["Projects"],"content":"Model Space -\u003e World Space $$rotate-z(\\theta)= \\begin{bmatrix} cos\\theta \u0026 -sin\\theta \u0026 0 \u0026 0\\\\ sin\\theta \u0026 cos\\theta \u0026 0 \u0026 0\\\\ 0 \u0026 0 \u0026 1 \u0026 0\\\\ 0 \u0026 0 \u0026 0 \u0026 1\\\\ \\end{bmatrix}$$ $$rotate-x(\\theta)= \\begin{bmatrix} 1 \u0026 0 \u0026 0 \u0026 0\\\\ 0 \u0026 cos\\theta \u0026 -sin\\theta \u0026 0\\\\ 0 \u0026 sin\\theta \u0026 cos\\theta \u0026 0\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix}$$ $$rotate-y(\\theta)= \\begin{bmatrix} cos\\theta \u0026 0 \u0026 sin\\theta \u0026 0\\\\ 0 \u0026 1 \u0026 0 \u0026 0\\\\ -sin\\theta \u0026 0 \u0026 cos\\theta \u0026 0\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix}$$ ","date":"2021-11-08","objectID":"/posts/projects/gzrender/:2:1","tags":["Graphics","C++"],"title":"GzRender","uri":"/posts/projects/gzrender/"},{"categories":["Projects"],"content":"World Space -\u003e Camera Space Assume $u,v,w$ is three base vectors in Camera Space, and the position of camera is $e$ $$M_{cam}= \\begin{bmatrix} x_u \u0026 y_u \u0026 z_u \u0026 0\\\\ x_v \u0026 y_v \u0026 z_v \u0026 0\\\\ x_w \u0026 y_w \u0026 z_w \u0026 0\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix} \\begin{bmatrix} 1 \u0026 0 \u0026 0 \u0026 -x_e\\\\ 0 \u0026 1 \u0026 0 \u0026 -y_e\\\\ 0 \u0026 0 \u0026 1 \u0026 -z_e\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix}$$ $$w=\\frac{g}{\\parallel g\\parallel}$$ $$u=\\frac{t\\times w}{\\parallel t\\times w\\parallel}$$ $$v=w\\times v$$ ","date":"2021-11-08","objectID":"/posts/projects/gzrender/:2:2","tags":["Graphics","C++"],"title":"GzRender","uri":"/posts/projects/gzrender/"},{"categories":["Projects"],"content":"Camera Space -\u003e Perspective Space $$M_{perspective}=\\begin{bmatrix} 1 \u0026 0 \u0026 0 \u0026 0\\\\ 0 \u0026 1 \u0026 0 \u0026 0\\\\ 0 \u0026 0 \u0026 1/d \u0026 0\\\\ 0 \u0026 0 \u0026 1/d \u0026 1 \\end{bmatrix}$$ Use fourth dimension to make perspective effect. ","date":"2021-11-08","objectID":"/posts/projects/gzrender/:2:3","tags":["Graphics","C++"],"title":"GzRender","uri":"/posts/projects/gzrender/"},{"categories":["Projects"],"content":"Perspective Space -\u003e Screen Space $xs$ means the number of pixels in screen width. $ys$ means the number of pixels in screen height $$M_{screen}=\\begin{bmatrix} xs/2 \u0026 0 \u0026 0 \u0026 xs/2\\\\ 0 \u0026 -ys/2 \u0026 0 \u0026 ys/2\\\\ 0 \u0026 0 \u0026 MAXINT \u0026 0\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix}$$ ","date":"2021-11-08","objectID":"/posts/projects/gzrender/:2:4","tags":["Graphics","C++"],"title":"GzRender","uri":"/posts/projects/gzrender/"},{"categories":["Projects"],"content":"Shading $$Color=(K_s\\sum_{l}l_e(R\\cdot E)^s) + (K_d\\sum_{l}l_e(N\\cdot L))+(K_al_a)$$ Phong Shading: interpolate nomals. Gouraud Shading: interpolate colars. ","date":"2021-11-08","objectID":"/posts/projects/gzrender/:3:0","tags":["Graphics","C++"],"title":"GzRender","uri":"/posts/projects/gzrender/"},{"categories":["Projects"],"content":"Texture ","date":"2021-11-08","objectID":"/posts/projects/gzrender/:4:0","tags":["Graphics","C++"],"title":"GzRender","uri":"/posts/projects/gzrender/"},{"categories":null,"content":"Binary Search 2064. Minimized Maximum of Products Distributed to Any Store ","date":"2021-11-07","objectID":"/posts/leetcode-single/2000/2064/:0:0","tags":["Binary Search","Leetcode","Algorithm"],"title":"2064. Minimized Maximum of Products Distributed to Any Store","uri":"/posts/leetcode-single/2000/2064/"},{"categories":null,"content":"Problem Given a integer array containing m elements, we want to split the element to get a new array with n elements. The largest element of the new array is maxn, find the minimum value of maxn. ","date":"2021-11-07","objectID":"/posts/leetcode-single/2000/2064/:1:0","tags":["Binary Search","Leetcode","Algorithm"],"title":"2064. Minimized Maximum of Products Distributed to Any Store","uri":"/posts/leetcode-single/2000/2064/"},{"categories":null,"content":"Idea Binary Search Each element x in the original array needs to occupy $\\lceil$x/maxn$\\rceil$ positions in the split array. We use the binary search method to find maxn so that the number of positions in the split array is equal to n. Left part makes the size of new array greater than n. Right part makes the size of new array smaller than n. ","date":"2021-11-07","objectID":"/posts/leetcode-single/2000/2064/:2:0","tags":["Binary Search","Leetcode","Algorithm"],"title":"2064. Minimized Maximum of Products Distributed to Any Store","uri":"/posts/leetcode-single/2000/2064/"},{"categories":null,"content":"Code class Solution { public: int minimizedMaximum(int n, vector\u003cint\u003e\u0026 quantities) { int left=1, right=100000; while(left\u003cright){ int mid=left+(right-left)/2; int countOfStore=0; for(int q: quantities){ countOfStore+=(q+mid-1)/mid; } if(countOfStore\u003en){ left=mid+1; }else if(countOfStore\u003c=n){ right=mid; } } return left; } }; ","date":"2021-11-07","objectID":"/posts/leetcode-single/2000/2064/:3:0","tags":["Binary Search","Leetcode","Algorithm"],"title":"2064. Minimized Maximum of Products Distributed to Any Store","uri":"/posts/leetcode-single/2000/2064/"},{"categories":null,"content":"I am now a CS graduate student at USC. I’m interested in React, Computer Graphics, GoLang. ‘I write the blog site to record my own learning process. I hope my article can help you. ","date":"2021-10-25","objectID":"/about/:0:0","tags":null,"title":"About","uri":"/about/"},{"categories":["CSCI-570 Analysis of Algorithm"],"content":"This article introduces the maximum flow problem. ","date":"2021-10-25","objectID":"/posts/algorithm/max-flow/:0:0","tags":["Algorithm"],"title":"Maximum Flow","uri":"/posts/algorithm/max-flow/"},{"categories":["CSCI-570 Analysis of Algorithm"],"content":"1. Problem Statement Flow Networks：a directed graph $G=(E, V)$ with the following features: Associated with each edge e is a capacity, which is nonnegative number that we denote $c_e$. There is a single source node $s\\in V$. There is a single sink node $t\\in V$. Assumptions about the flow networks we deal with: No edge enters the source $s$ and no edge leaves the sink $t$. At least one edge incident to each node. All capacities are integers Flow: An s-t flow is a function f that maps each edge e to a nonnegative real number, $f : E \\to \\mathbf{R} ^+$; the value $f(e)$ intuitively represents the amount of flow carried by edge $e$. A flow f must satisfy the following two properties. (Capacity conditions) For each $e\\in E$, we have $0\\leq f(e)\\leq c_e$. (Conservation conditions) For each node $v$ other than $s$ and $t$, we have $$\\sum_{e\\ into\\ v} f(e)=\\sum_{e\\ out\\ of\\ v} f(e)$$ The value of a flow, denoted $v(f)$, is defined to be the amount of flow generated at the source: $$v(f)=\\sum_{e\\ out\\ of\\ s} f(e)$$ The Maximum-Flow Problem: Given a flow network, find a flow of maximum posiible value. ","date":"2021-10-25","objectID":"/posts/algorithm/max-flow/:1:0","tags":["Algorithm"],"title":"Maximum Flow","uri":"/posts/algorithm/max-flow/"},{"categories":["CSCI-570 Analysis of Algorithm"],"content":"2. Present a Solution The Residual Graph: Given a flow network $G$, and a flow $f$ on $G$, we define the residual graph $G_f$ of G with repect to f as follows. The node set of $G_f$ is the same as that of $G$. For each edge $e=(u,v)$ of $G$, if $f(e)\u003cc_e$, it indicages that there are $c_e-f(e)$ “leftover” units of capacity on which we could try pushing flow forward. So we include the edge $e=(u,v)$ in $G_f$, with a capacity of $c_e-f(e)$. We will call edges included this way forward edges. For each edge $e=(u,v)$ of $G$ on which $f(e)\u003e0$, there are $f(e)$ units of flow that we can “undo” if we want to, by pushing flow backward. So we include the edge $e^\\prime = (v, u)$ in $G_f$ , with a capacity of $f(e)$. Note that $e^\\prime$ has the same ends as $e$, but its direction is reversed; we will call edges included this way backward edges. Augmenting Paths in a Residual Graph Assume we have a flow of a network, we want to increase the value of the flow. The method is to find a s-t path $P$ in $G_f$, we define $bottleneck(P,f)$ to be the minimum residual capacity of any edge on $P$. For each edge belong to $P$, if it’s a forward edge, increase $f(e)$ by $bottleneck(P, f)$, if it’s a backward edge, decrease $f(e)$ in $G$ by $bottleneck(P, f)$. Ford-Fulkerson Algorithm Max-Flow Initially $f(e) = 0$ for all $e$ in $G$ While there is an s-t path in the residual graph $G_f$ Let $P$ be a simple s-t path in $G_f$ $f^\\prime$ = augment($f$, $P$) Update $f$ to be $f^\\prime$ Update the residual graph $G_f$ to be $G_f^\\prime$ Endwhile Return $f$ ","date":"2021-10-25","objectID":"/posts/algorithm/max-flow/:2:0","tags":["Algorithm"],"title":"Maximum Flow","uri":"/posts/algorithm/max-flow/"},{"categories":["CSCI-570 Analysis of Algorithm"],"content":"3. Prove Crectness definition: s-t cut: a partition (A, B) of the vertex set V, so that $s\\in A$ and $t\\in B$ the capacity of a cut(A, B): $c(A, B)=\\sum_{e\\ out\\ of\\ A}c_e$ some conclusions: Let $f$ be any s-t flow, and (A, B) any s-t cut. Then $v(f) = f^{out}(A) − f^{in}(A)=f^{in}(B) − f^{out}(B)$. Let f be any s-t flow, and (A, B) any s-t cut. Then $v(f ) \\leq c(A, B)$. important conclusions: If $f$ is an s-t flow such that there is no s-t path in the residual graph $G_f$, then there is an s-t cut $(A^\\ast, B^\\ast)$ in $G$ for which $v(f) = c(A^\\ast, B^\\ast)$. Consequently, $f$ has the maximum value of any flow in $G$, and $(A^\\ast, B^\\ast)$ has the minimum capacity of any s-t cut in $G$. When Fork-Furkerson Algorithm terminates, let $A^*$ denote the set of all nodes v in G for which there is an s-v path in $G_f$. Let $B^\\ast$ denote the set of all other nodes: $B^\\ast = V − A^\\ast$. ","date":"2021-10-25","objectID":"/posts/algorithm/max-flow/:3:0","tags":["Algorithm"],"title":"Maximum Flow","uri":"/posts/algorithm/max-flow/"},{"categories":["CSCI-570 Analysis of Algorithm"],"content":"4. Analysis of Time Complexity definition: $C=\\sum_{e\\ out\\ of\\ s}c_e$ **some conclusion**: Suppose, as above, that all capacities in the flow network $G$ are integers. Then the Ford-Fulkerson Algorithm terminates in at most $C$ iterations of the While loop. All capacities in the flow network $G$ are integers. Then the Ford-Fulkerson Algorithm can be implemented to run in $O(mC)$ time. Scaling Fork-Fulkerson Algorithm When choosing augmenting paths wisely, the Fork-Fulkerson Algorithm can be accelerated. Let $G_f(\\Delta)$ be the subset of the residual graph consisting only of edges with residual capacity of at least $\\Delta$. Scaling Max-Flow Initially f(e) = 0 for all e in G Initially set $\\Delta$ to be the largest power of 2 that is no larger than the maximum capacity out of s: $\\Delta \\leq max_{e\\ out\\ of\\ s} c_e$ While $\\Delta\\geq1$ While there is an s-t path in the graph $G_f(\\Delta)$ Let P be a simple s-t path in $G_f(\\Delta)$ $f^\\prime$ = augment(f , P) Update f to be $f^\\prime$ and update $G_f(\\Delta)$ Endwhile $\\Delta=\\Delta/2$ Endwhile Return f Time Complexity of scaling version of Fork-Fulkerson Algorithm is $O(m^2log_2C)$ ","date":"2021-10-25","objectID":"/posts/algorithm/max-flow/:4:0","tags":["Algorithm"],"title":"Maximum Flow","uri":"/posts/algorithm/max-flow/"},{"categories":["CSCI-570 Analysis of Algorithm"],"content":"5. Applications of Maximum Flow ","date":"2021-10-25","objectID":"/posts/algorithm/max-flow/:5:0","tags":["Algorithm"],"title":"Maximum Flow","uri":"/posts/algorithm/max-flow/"},{"categories":["CSCI-570 Analysis of Algorithm"],"content":"5.1. The Bipartite Matching Problem Definition: bipartite graph $G = (V , E)$ is an undirected graph whose node set can be partitioned as $V = X \\cup Y$, with the property that every edge $e \\in E$ has one end in $X$ and the other end in $Y$. A matching $M$ in $G$ is a subset of the edges $M \\subseteq E$ such that each node appears in at most one edge in $M$. The Bipartite Matching Problem is that of finding a matching in $G$ of largest possible size. Turn this problem into a maximum flow problem: Proof: To prove this we should show that $G^\\prime$ will have a max flow of value k if and only if $G$’s maximum size of matching is k. ","date":"2021-10-25","objectID":"/posts/algorithm/max-flow/:5:1","tags":["Algorithm"],"title":"Maximum Flow","uri":"/posts/algorithm/max-flow/"},{"categories":["CSCI-570 Analysis of Algorithm"],"content":"5.2. Edge-Disjoint Path in Directed and Undirected Graph Edge-Disjoint Path in Directed Graph: Delete the edges ending at source and edges begining at sink. Edge-Disjoint Path in Undirected Graph: Transfer the original undirected edge to two directed edges with reverse directions. Then this problem is similar to Edge-Disjoint Path in Directed Graph. However, we should pay attention to a case: one path uses directed edge (u, v) and another path uses directed edge (v, u). It is not hard to see that there always exists a maximum flow in any network that uses at most one out of each pair of oppositely directed edges. ","date":"2021-10-25","objectID":"/posts/algorithm/max-flow/:5:2","tags":["Algorithm"],"title":"Maximum Flow","uri":"/posts/algorithm/max-flow/"},{"categories":["CSCI-570 Analysis of Algorithm"],"content":"5.3. Node-Disjoint Path ","date":"2021-10-25","objectID":"/posts/algorithm/max-flow/:5:3","tags":["Algorithm"],"title":"Maximum Flow","uri":"/posts/algorithm/max-flow/"},{"categories":["CSCI-570 Analysis of Algorithm"],"content":"5.4. Circulations with Demands Definition: Circulation Network: We are given a directed graph $G=(V,E)$ with capacities on edges Associated with each node $v\\in V$ a demand $d_v$ If $d_v\u003e0$, node v has demand of $d_v$ as a sink. If $d_v\u003c0$, node v has supply of $d_v$ as a source. If $d_v=0$, v is neither a sink and source. Circulation: We say that a circulation with demands ${d_v}$ is a function $f$ that assigns a nonnegative real number to each edge and satisfies the following two conditions. (Capacity conditions)For each $e\\in E$, we have $0\\leq f(e)\\leq c_e$. (Demand conditions)For each $v\\in V$, we have v, $f^{in}(v)−f^{out}(v)=d_v$. Our problem is if there is a feasible circulation in a circulation network. Solution: ","date":"2021-10-25","objectID":"/posts/algorithm/max-flow/:5:4","tags":["Algorithm"],"title":"Maximum Flow","uri":"/posts/algorithm/max-flow/"},{"categories":["CSCI-570 Analysis of Algorithm"],"content":"5.5 Circulation with Demands and Lower Bounds Definition: (Capacity conditions)For each $e\\in E$, we have $l_e\\leq f(e)\\leq c_e$. (Demand conditions)For each $v\\in V$, we have v, $f^{in}(v)−f^{out}(v)=d_v$. Solution: Satisfying lower bounds first, then the problem is similar to Circulation with Demands ","date":"2021-10-25","objectID":"/posts/algorithm/max-flow/:5:5","tags":["Algorithm"],"title":"Maximum Flow","uri":"/posts/algorithm/max-flow/"},{"categories":["CSCI-570 Analysis of Algorithm"],"content":"5.6 Min Flow Problem Every edge has a lower bound. Find a feasible flow of minimum possible value. Solution: Assign large capacity to all edges and find a feasible flow $f$ construct $G'$, where all the edges are reversed and the reversed edge $e$ has capacity = $f_e-l_e$ Find maximum flow $f'$ from $t$ to $s$. min flow = $f-f'$ ","date":"2021-10-25","objectID":"/posts/algorithm/max-flow/:5:6","tags":["Algorithm"],"title":"Maximum Flow","uri":"/posts/algorithm/max-flow/"},{"categories":["Projects"],"content":"A education game about learning English vocabulary. ","date":"2020-02-28","objectID":"/posts/projects/word-pyramid/:0:0","tags":["APP","Game"],"title":"Word Pyramid","uri":"/posts/projects/word-pyramid/"},{"categories":["Projects"],"content":"Why develop this game? Why is it so easy for people to indulge in games, but not to work and study? Because there is a complete set of psychological methods behind the game to guide you to indulge in it, including instant feedback, stage goals, virtual game items, random lottery… I was thinking that if the game mechanics and learning are combined can people also indulge in learning? Based on these ideas, and it happens that the Covid-19 pandemic has given me a lot of time at home, I turned this idea into a mobile game. ","date":"2020-02-28","objectID":"/posts/projects/word-pyramid/:1:0","tags":["APP","Game"],"title":"Word Pyramid","uri":"/posts/projects/word-pyramid/"},{"categories":["Projects"],"content":"What’s the game? This is a business game. Players earn gold coins by memorizing English words. The gold coins can be used to build houses and open up the land. Although it looks like a game at first glance, it is actually a complete word recitation app. As a former TOEFL test taker, I divided the TOEFL words into categories based on my experience. Some lists are subject words, and some lists are words that are easy to confuse. I also try to keep the Chinese meaning of words concise, so that we can recite the words more efficiently. In addition, this APP also supports word pronunciation. This game has been put on the APP Store, download link ","date":"2020-02-28","objectID":"/posts/projects/word-pyramid/:2:0","tags":["APP","Game"],"title":"Word Pyramid","uri":"/posts/projects/word-pyramid/"},{"categories":["Projects"],"content":"How to develope this game? I completed the design, development, and art of the game alone. The entire game is developed based on the Unity engine, Krita is used to draw the UI, and MagicaPixel is used for 3D modeling. ","date":"2020-02-28","objectID":"/posts/projects/word-pyramid/:3:0","tags":["APP","Game"],"title":"Word Pyramid","uri":"/posts/projects/word-pyramid/"},{"categories":["Projects"],"content":"Next steps At present, this game has achieved 200+ downloads and a 5.0 rating at App Store. My next plan is: Make some changes to the design, adding guidance to allow players to understand the game more quickly. Make some optimizations to the art, adding the switch between night and day. Add more word libraries. ","date":"2020-02-28","objectID":"/posts/projects/word-pyramid/:4:0","tags":["APP","Game"],"title":"Word Pyramid","uri":"/posts/projects/word-pyramid/"},{"categories":["Networks"],"content":"OSI Model 7 Layers of OSI Model: Layer Function 1 Physical Transmission and reception of raw bit streams over a physical medium 2 Data link Reliable transmission of data frames between two nodes connected by a physical layer 3 Networking Structuring and managing a multi-node network, includingaddressing, routing and traffic control 4 Transport Reliable transmission of data segments between points on a network, includingsegmentation, acknowledgement and multiplexing 5 Session Managing communicationsessions, i.e., continuous exchange of information in the form of multiple back-and-forth transmissions between two nodes 6 Presentation Translation of data between a networking service and an application; includingcharacter encoding, data compression and encryption/decryption 7 Application High-levelAPIs, including resource sharing, remote file access Physical layer, data link layer and network layer are called media layers, transport layer, session layer, presentation layer and application layer are called host layers. ","date":"2020-01-07","objectID":"/posts/networks/osi-tcpip/:1:0","tags":["Networks"],"title":"OSI model and TCP/IP model","uri":"/posts/networks/osi-tcpip/"},{"categories":["Networks"],"content":"TCP/IP Model The Internet application layer maps to the OSI application layer, presentation layer, and most of the session layer. The TCP/IP transport layer maps to the graceful close function of the OSI session layer as well as the OSI transport layer. The internet layer performs functions as those in a subset of the OSI network layer. The link layer corresponds to the OSI data link layer and may include similar functions as the physical layer, as well as some protocols of the OSI’s network layer. ","date":"2020-01-07","objectID":"/posts/networks/osi-tcpip/:2:0","tags":["Networks"],"title":"OSI model and TCP/IP model","uri":"/posts/networks/osi-tcpip/"},{"categories":null,"content":"Notes of ReactJS document ` ` ","date":"2020-01-03","objectID":"/posts/frontend/reactjs/:0:0","tags":["React"],"title":"ReactJS","uri":"/posts/frontend/reactjs/"},{"categories":null,"content":"2. JSX Embedding Expressions in JSX using curly braces const name = 'Josh Perez'; const element = \u003ch1\u003eHello, {name}\u003c/h1\u003e; We split JSX over multiple lines for readability. While it isn’t required, when doing this, we also recommend wrapping it in parentheses to avoid the pitfalls of automatic semicolon insertion. JSX is an expression too Specifying Attributes with JSX const element = \u003cdiv tabIndex=\"0\"\u003e\u003c/div\u003e; const element = \u003cimg src={user.avatarUrl}\u003e\u003c/img\u003e; Empty tag ends in /\u003e const element = \u003cimg src={user.avatarUrl} /\u003e; JSX Prevents Injection Attacks: Everything is converted to a string before being rendered. JSX represents objects. ","date":"2020-01-03","objectID":"/posts/frontend/reactjs/:1:0","tags":["React"],"title":"ReactJS","uri":"/posts/frontend/reactjs/"},{"categories":null,"content":"3. Rendering Elements Elements are the smallest building blocks of React apps. ","date":"2020-01-03","objectID":"/posts/frontend/reactjs/:2:0","tags":["React"],"title":"ReactJS","uri":"/posts/frontend/reactjs/"},{"categories":null,"content":"4. Components and Props Always start component names with a capital letter. All React components must act like pure functions with respect to their props. ","date":"2020-01-03","objectID":"/posts/frontend/reactjs/:3:0","tags":["React"],"title":"ReactJS","uri":"/posts/frontend/reactjs/"},{"categories":null,"content":"5. State and Lifecycle There things about setState() Do not modify state directly State updates may be asynchronous use function to update state that relies on previous state this.setState((state, props) =\u003e ({ counter: state.counter + props.increment })); State updated are merged ","date":"2020-01-03","objectID":"/posts/frontend/reactjs/:4:0","tags":["React"],"title":"ReactJS","uri":"/posts/frontend/reactjs/"},{"categories":null,"content":"6. Handling Events camelCase pass a function as the event handler \u003cbutton onClick={activateLasers}\u003e Activate Lasers \u003c/button\u003e call preventDefault explicitly to prevent default behavior Three ways to handle this in React use bind in constructor constructor(props) { super(props); this.state = {isToggleOn: true}; // This binding is necessary to make `this` work in the callback this.handleClick = this.handleClick.bind(this); } use array function handleClick = () =\u003e { console.log('this is:', this); } use array function in the callback. The potential drawback is if this callback is passed as a prop to lower components, those components might do an extra re-rendering. render() { // This syntax ensures `this` is bound within handleClick return ( \u003cbutton onClick={() =\u003e this.handleClick()}\u003e Click me \u003c/button\u003e ); } ","date":"2020-01-03","objectID":"/posts/frontend/reactjs/:5:0","tags":["React"],"title":"ReactJS","uri":"/posts/frontend/reactjs/"},{"categories":null,"content":"7. Conditional Rendering Element Variables Inline If with logical \u0026\u0026 operator {unreadMessages.length \u003e 0 \u0026\u0026 \u003ch2\u003e You have {unreadMessages.length} unread messages. \u003c/h2\u003e } Inline if-else with conditional operator {isLoggedIn ? \u003cLogoutButton onClick={this.handleLogoutClick} /\u003e : \u003cLoginButton onClick={this.handleLoginClick} /\u003e } Preventing component from rendering: return null ","date":"2020-01-03","objectID":"/posts/frontend/reactjs/:6:0","tags":["React"],"title":"ReactJS","uri":"/posts/frontend/reactjs/"},{"categories":null,"content":"8. Lists and Keys Rendering multiple components const numbers = [1, 2, 3, 4, 5]; const listItems = numbers.map((number) =\u003e \u003cli\u003e{number}\u003c/li\u003e ); Basic list components function NumberList(props) { const numbers = props.numbers; const listItems = numbers.map((number) =\u003e \u003cli key={number.toString()}\u003e {number} \u003c/li\u003e ); return ( \u003cul\u003e{listItems}\u003c/ul\u003e ); } We don’t recommend using indexes for keys if the order of items may change. if you extract a ListItem component, you should keep the key on the \u003cListItem /\u003e elements in the array rather than on the \u003cli\u003e element in the ListItem itself. function ListItem(props) { // Correct! There is no need to specify the key here: return \u003cli\u003e{props.value}\u003c/li\u003e; } function NumberList(props) { const numbers = props.numbers; const listItems = numbers.map((number) =\u003e // Correct! Key should be specified inside the array. \u003cListItem key={number.toString()} value={number} /\u003e ); return ( \u003cul\u003e {listItems} \u003c/ul\u003e ); } Keys must only be unique among siblings ","date":"2020-01-03","objectID":"/posts/frontend/reactjs/:7:0","tags":["React"],"title":"ReactJS","uri":"/posts/frontend/reactjs/"},{"categories":null,"content":"9. Forms Input something class NameForm extends React.Component { constructor(props) { super(props); this.state = {value: ''}; this.handleChange = this.handleChange.bind(this); this.handleSubmit = this.handleSubmit.bind(this); } handleChange(event) { this.setState({value: event.target.value}); } handleSubmit(event) { alert('A name was submitted: ' + this.state.value); event.preventDefault(); } render() { return ( \u003cform onSubmit={this.handleSubmit}\u003e \u003clabel\u003e Name: \u003cinput type=\"text\" value={this.state.value} onChange={this.handleChange} /\u003e \u003c/label\u003e \u003cinput type=\"submit\" value=\"Submit\" /\u003e \u003c/form\u003e ); } } ","date":"2020-01-03","objectID":"/posts/frontend/reactjs/:8:0","tags":["React"],"title":"ReactJS","uri":"/posts/frontend/reactjs/"},{"categories":null,"content":"An operating System is a program that manages the computer hardware. It also provides a basis for Application Programs and acts as an internediary between computer User and computer Hardware. Functions of OS: It is a interface between Use \u0026 Hardware Allocation of Resources Management of Memory, Security, etc. ","date":"2019-12-13","objectID":"/posts/os/:0:0","tags":null,"title":"OS","uri":"/posts/os/"},{"categories":null,"content":"Structure of Operation System A modern general-purpose computer system consists of one or more CPUs and a number of device controllers connected through a common bus that provides access to shared memory. Each device controller is in charge of a specific type of device The CPU and the device controllers can execute concurrently, competing for memory cycles. To ensure orderly access to the shared memory, a memory controller is provided whose function is to synchronize access to the memory. Some inportant terms: Bootstrap Program: The initial program that runs when a computer is powered up or rebooted. It is stored in the ROM It must know how to load the OS and start executing that system It must locate and load into memory the OS Kernel Interrupt: The occurence of an event is usually signalled by an interrupt from hardware and software Hardware may trigger an interrupt at any time by sending a signal to the CPU, usually by the way of the system bus. When the CPU is interrupted, it stops what it is doing and immediately transfers execution to a fixed location. The fixed location usually contains the starting address where the Service Routine of the interrupt is located. The Interrupt Service Routine Executes. On completion, the CPU resumes the interrupted computation. System Call: Software may trigger an interrupt by executing a special operation called System Call. ","date":"2019-12-13","objectID":"/posts/os/:1:0","tags":null,"title":"OS","uri":"/posts/os/"},{"categories":null,"content":"Storage Structure Registers Cache Main Memory （RAM） Everything that executes in computer should load to main memory first Electronic Disk Magnetic Disk Optical Disk Volatile: Loses its contents when power is removed. Registers, Cache, Main Memory Non Volatile: Retains its contents even when power is removed. Electronic Disk ","date":"2019-12-13","objectID":"/posts/os/:2:0","tags":null,"title":"OS","uri":"/posts/os/"},{"categories":null,"content":"I/O Structure Storage is only one of many types of I/O devices within a computer A large portion of operating system code is dedicated to managing I/O, both because of its importance to the reliability and performance of a system and because of the varying nature of the devices. A general-purpose computer system consists of CPUs and multiple device controllers that are connected through a common bus. Each device controller maintains Local Buffer Storage and Set of Special Purpose Registers Typically, operating systems have a device driver for each device controller This device driver understands the device controller and presents a uniform interface to the device to the rest of operating system. Working of an I/O Operation: ","date":"2019-12-13","objectID":"/posts/os/:3:0","tags":null,"title":"OS","uri":"/posts/os/"},{"categories":null,"content":"Computer System Architecture Types of Computer System based on number of General Purpose Processors: Single Processor Systems One main CPU capable of executing a general purpose instruction set including instructions from user processor. Other special purpose processors are also present which perform device specific tasks. Multiprocessor Systems Clustered Systems ","date":"2019-12-13","objectID":"/posts/os/:4:0","tags":null,"title":"OS","uri":"/posts/os/"},{"categories":["Misc"],"content":"How to install and config Nginx in your server. ","date":"2019-07-25","objectID":"/posts/misc/how-to-build-nginx-server/:0:0","tags":["Nginx"],"title":"How to build a Nginx server","uri":"/posts/misc/how-to-build-nginx-server/"},{"categories":["Misc"],"content":"Installing Nginx sudo apt-get update sudo apt-get install nginx # Check if the installation is successful nginx -v Some folders about Nginx /usr/src/nginx : main program /etc/nginx : store config files /usr/share/nginx : store static files /var/log/nginx : store log ","date":"2019-07-25","objectID":"/posts/misc/how-to-build-nginx-server/:1:0","tags":["Nginx"],"title":"How to build a Nginx server","uri":"/posts/misc/how-to-build-nginx-server/"},{"categories":["Misc"],"content":"Configuring Nginx This section is about config files. /etc/nginx/nginx.conf Some default content is in the file. We need to make some changes to this file. Change the first line to “user root” In http block, add “include /etc/nginx/conf.d/*.conf;” user root; #!!this line is important worker_processes auto; pid /run/nginx.pid; events { worker_connections 768; # multi_accept on; } http { ## # Basic Settings ## sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; # server_tokens off; # server_names_hash_bucket_size 64; # server_name_in_redirect off; include /etc/nginx/mime.types; default_type application/octet-stream; ## # SSL Settings ## ssl_protocols TLSv1 TLSv1.1 TLSv1.2; # Dropping SSLv3, ref: POODLE ssl_prefer_server_ciphers on; ## # Logging Settings ## access_log /var/log/nginx/access.log; error_log /var/log/nginx/error.log; ## # Gzip Settings ## gzip on; gzip_disable \"msie6\"; # gzip_vary on; # gzip_proxied any; # gzip_comp_level 6; # gzip_buffers 16 8k; # gzip_http_version 1.1; # gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript; ## # Virtual Host Configs ## # !!add the config file we write!! include /etc/nginx/conf.d/*.conf; #include /etc/nginx/sites-enabled/*; } #mail { # # See sample authentication script at: # # http://wiki.nginx.org/ImapAuthenticateWithApachePhpScript # # # auth_http localhost/auth.php; # # pop3_capabilities \"TOP\" \"USER\"; # # imap_capabilities \"IMAP4rev1\" \"UIDPLUS\"; # # server { # listen localhost:110; # protocol pop3; # proxy on; # } # # server { # listen localhost:143; # protocol imap; # proxy on; # } #} /etc/nginx/conf.d/default.conf We have included this file in /etc/nginx/nginx.conf. This file is our core configuration where we associate the path in the URL with the folder on the server. server { listen 80; server_name **.**.***.***; location / { root /usr/share/nginx/html/pc; #Forward the request to this directory index index.html allow all; } location ~/api/ { #Forward the request to backend proxy_pass http://**.**.***.***:8080; } location ~/livecode/ {# configure websocket proxy_pass http://**.**.***.***:8080; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \"upgrade\"; } } ","date":"2019-07-25","objectID":"/posts/misc/how-to-build-nginx-server/:2:0","tags":["Nginx"],"title":"How to build a Nginx server","uri":"/posts/misc/how-to-build-nginx-server/"},{"categories":["Misc"],"content":"Nginx common commands nginx #start nginx service nginx -s stop #stop nginx service immediately nginx -s quit #stop nginx service after it finishes current tasks nginx -t #check the configuration of nginx is valid nginx -s reload # restart nginx service netstat -tnlp # view port occupancy ","date":"2019-07-25","objectID":"/posts/misc/how-to-build-nginx-server/:3:0","tags":["Nginx"],"title":"How to build a Nginx server","uri":"/posts/misc/how-to-build-nginx-server/"},{"categories":["Projects"],"content":"A mini Minecraft game Play it here Github repository The layout of the page is like this: ⚠️ Please make sure your input now is English input, otherwise the operation involving the keyboard is invalid. 🍀How to start When your mouse moves in the canvas, there is a red cube following your cursor, left click your mouse, you will see an object show up in your canvas. It’s really simple. Here are some other operation involving keyboard. Change the view: w a s d Delete object: press Shift + click the object Rotate object by 90°: press Alt + click the object Rotate object: press Shift + Alt + click the object Ambient light: ⬆️ press ‘=’ ⬇️ press ‘-’ Change the place of the light source: i k j l m n 🍀Other tips When you input color, you can input the color name directly like blue, yellow, pink, etc. This website indicates the color names that is recognized by Block http://www.w3school.com.cn/cssref/css_colornames.asp You can also input ‘#’ + RGB value, like #00ffff. When you change the light color, you must input “0x” + rgb value, eg: 0x00ffff 🌸Some examples ","date":"2019-01-09","objectID":"/posts/projects/block/:0:0","tags":["Graphics","Game"],"title":"Block","uri":"/posts/projects/block/"},{"categories":["Projects"],"content":"Two algorithm extracting key frames in a video. Github Repository It contains two algorithm extracting key frame. Before explaining them, I say something about comparing the similarity of tow images. In the next two algorithms, I use hash number of image to compare the similarity of two pictures. This algorithm is from click here！ . ","date":"2019-01-07","objectID":"/posts/projects/extractkeyframe/:0:0","tags":["C++"],"title":"ExtractKeyFrame","uri":"/posts/projects/extractkeyframe/"},{"categories":["Projects"],"content":"Algorithm 1 It‘s a very simple algorithm to extract key frame. Step 1: Extract one frame from each 30 frames. Step 2: Compare the frame with the last frame. If they are similar, I discard it. Otherwise, I regard it as a keyframe. Step 3: Discard the frame that is nearly black. The result of the Algorithm 1: ","date":"2019-01-07","objectID":"/posts/projects/extractkeyframe/:1:0","tags":["C++"],"title":"ExtractKeyFrame","uri":"/posts/projects/extractkeyframe/"},{"categories":["Projects"],"content":"Algorithm 2 Algorithm 2 is a little advanced. I referenced an ancient paper(Yueting Zhuang, Yong Rui, Thomas S. Huang, Sharad Mehrotra., Adaptive Key Frame Extraction Using Unsupervised Clustering, IEEE ICIP'98, Chicago, USA, 98.10.) But the difference is I compare the similarity of two images by a different method mentioned above. The result of Algorithm 2: ","date":"2019-01-07","objectID":"/posts/projects/extractkeyframe/:2:0","tags":["C++"],"title":"ExtractKeyFrame","uri":"/posts/projects/extractkeyframe/"}]